{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(\n",
    "    'gs://kaggle-model-experiments/resources/civil_comments_data/artificial_bias/fprost/20181012170507',\n",
    "    'train_artificial_bias-00001-of-00004.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_civil_comments_spec():\n",
    "  spec = {\n",
    "      'comment_text': tf.FixedLenFeature([], dtype=tf.string),\n",
    "      'id': tf.FixedLenFeature([], dtype=tf.string),\n",
    "      'toxicity': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "      'severe_toxicity': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "      'obscene': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "      'sexual_explicit': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "      'identity_attack': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "      'insult': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "      'threat': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "      'toxicity_annotator_count': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "      'identity_annotator_count': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    }\n",
    "  for _id in ['male', 'female', 'transgender', 'other_gender', 'heterosexual', \n",
    "              'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation',\n",
    "              'christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist',\n",
    "              'other_religion', 'black', 'white', 'asian', 'latino', 'other_race_or_ethnicity',\n",
    "              'physical_disability', 'intellectual_or_learning_disability',\n",
    "              'psychiatric_or_mental_illness', 'other_disability']:\n",
    "    spec[_id] = tf.FixedLenFeature([], dtype=tf.float32, default_value=-1.)\n",
    "  return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD_IDENTITY = 0.5\n",
    "THRESHOLD_TOXICITY = 0.5\n",
    "\n",
    "count_total = 50000\n",
    "count_identity = 0\n",
    "count_male_toxic = 0\n",
    "count_male_non_toxic = 0\n",
    "count_female_toxic = 0\n",
    "count_female_non_toxic =0\n",
    "count_female_and_male_toxic = 0\n",
    "count_female_and_male_non_toxic = 0\n",
    "count_heterosexual_toxic = 0\n",
    "count_heterosexual_non_toxic = 0\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer([input_path], num_epochs=1)\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    parsed_element = tf.parse_single_example(\n",
    "              serialized=serialized_example,\n",
    "              features=get_civil_comments_spec(),\n",
    "    )\n",
    "\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(count_total):\n",
    "        el = sess.run([parsed_element])\n",
    "        el = el[0]\n",
    "\n",
    "        if el['male']>=0:\n",
    "            count_identity +=1\n",
    "\n",
    "            if el['male'] >= THRESHOLD_IDENTITY:\n",
    "                if el['toxicity'] >= THRESHOLD_TOXICITY:\n",
    "                    count_male_toxic += 1\n",
    "                else:\n",
    "                    count_male_non_toxic += 1\n",
    "            if el['female'] >= THRESHOLD_IDENTITY:\n",
    "                if el['toxicity'] >= THRESHOLD_TOXICITY:\n",
    "                    count_female_toxic += 1\n",
    "                else:\n",
    "                    count_female_non_toxic += 1\n",
    "            \n",
    "            if  el['male'] >= THRESHOLD_IDENTITY and el['female'] >= THRESHOLD_IDENTITY:\n",
    "                if el['toxicity'] >= THRESHOLD_TOXICITY:\n",
    "                    count_female_and_male_toxic += 1\n",
    "                else:\n",
    "                    count_female_and_male_non_toxic += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Number of examples seen: {}'.format(count_total))\n",
    "print ('Number of examples labeled for identity: {}'.format(count_identity))\n",
    "print\n",
    "print ('Number of examples that were male: {}'.format(count_male_toxic + count_male_non_toxic))\n",
    "print ('Ratio of examples that were male: {}'.format(float(count_male_toxic + count_male_non_toxic)/count_identity))\n",
    "print ('Ratio of toxic male example: {}'.format(float(count_male_toxic)/ (count_male_toxic + count_male_non_toxic)))\n",
    "print\n",
    "print ('Number of examples that were female: {}'.format(count_female_toxic + count_female_non_toxic))\n",
    "print ('Ratio of examples that were female: {}'.format(float(count_female_toxic + count_female_non_toxic)/count_identity))\n",
    "print ('Ratio of toxic female example: {}'.format(float(count_female_toxic)/ (count_female_toxic + count_female_non_toxic)))\n",
    "print\n",
    "print ('Number of examples that were female and male: {}'.format(count_female_and_male_toxic + count_female_and_male_non_toxic))\n",
    "print ('Ratio of toxic female and male example: {}'.format(float(count_female_and_male_toxic)/ (count_female_and_male_toxic + count_female_and_male_non_toxic)))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
